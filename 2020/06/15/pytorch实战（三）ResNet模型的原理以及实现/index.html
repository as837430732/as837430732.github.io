<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>pytorch实战（三） ResNet模型的原理以及实现 | Haoran's blog</title><meta name="description" content="使用pytorch实现ResNet"><meta name="keywords" content="Pytorch"><meta name="author" content="Haoran Gao"><meta name="copyright" content="Haoran Gao"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="pytorch实战（三） ResNet模型的原理以及实现"><meta name="twitter:description" content="使用pytorch实现ResNet"><meta name="twitter:image" content="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><meta property="og:type" content="article"><meta property="og:title" content="pytorch实战（三） ResNet模型的原理以及实现"><meta property="og:url" content="https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89ResNet%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"><meta property="og:site_name" content="Haoran's blog"><meta property="og:description" content="使用pytorch实现ResNet"><meta property="og:image" content="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><meta property="article:published_time" content="2020-06-15T12:09:58.000Z"><meta property="article:modified_time" content="2023-05-15T07:53:23.945Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89ResNet%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"><link rel="prev" title="日常备忘记录" href="https://as837430732.github.io/2020/08/25/%E6%97%A5%E5%B8%B8%E5%A4%87%E5%BF%98%E8%AE%B0%E5%BD%95/"><link rel="next" title="pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击" href="https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%8D%E7%8E%B0FGSM%E3%80%81DeepFool%E6%94%BB%E5%87%BB/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/avatar.png" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">13</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">8</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ResNet模型的原理以及实现"><span class="toc-text">ResNet模型的原理以及实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-实现MNIST数据集分类"><span class="toc-text">1 实现MNIST数据集分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-导入相应库、定义常量以及加载MNIST数据"><span class="toc-text">1.1 导入相应库、定义常量以及加载MNIST数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-定义模型"><span class="toc-text">1.2 定义模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-定义训练函数"><span class="toc-text">1.3 定义训练函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-定义测试函数"><span class="toc-text">1.4 定义测试函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-训练-保存模型-加载模型-测试"><span class="toc-text">1.5 训练+保存模型+加载模型+测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-实现FGSM攻击"><span class="toc-text">2 实现FGSM攻击</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-导入相应库，定义常量，加载模型"><span class="toc-text">2.1 导入相应库，定义常量，加载模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-实现FGSM"><span class="toc-text">2.2 实现FGSM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-实现DeepFool攻击"><span class="toc-text">3 实现DeepFool攻击</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-导入相应库，定义常量，加载模型"><span class="toc-text">3.1 导入相应库，定义常量，加载模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-实现DeepFool"><span class="toc-text">3.2 实现DeepFool</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-参考文献"><span class="toc-text">4 参考文献</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#附录"><span class="toc-text">附录</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Haoran's blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">pytorch实战（三） ResNet模型的原理以及实现</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-15 20:09:58"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-06-15</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2023-05-15 15:53:23"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2023-05-15</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/">实战</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="ResNet模型的原理以及实现"><a href="#ResNet模型的原理以及实现" class="headerlink" title="ResNet模型的原理以及实现"></a>ResNet模型的原理以及实现</h1><p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230515155301712.png" alt="image-20230515155301712"></p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230515155323170.png" alt="image-20230515155323170"></p>
<h2 id="1-实现MNIST数据集分类"><a href="#1-实现MNIST数据集分类" class="headerlink" title="1 实现MNIST数据集分类"></a>1 实现MNIST数据集分类</h2><h3 id="1-1-导入相应库、定义常量以及加载MNIST数据"><a href="#1-1-导入相应库、定义常量以及加载MNIST数据" class="headerlink" title="1.1 导入相应库、定义常量以及加载MNIST数据"></a>1.1 导入相应库、定义常量以及加载MNIST数据</h3><ul>
<li>导入库</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span>  *</span><br></pre></td></tr></table></figure>
<ul>
<li>定义常量：批处理大小，设备</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">256</span></span><br><span class="line">DEVICE = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>利用torchvision加载MNIST数据集，图像数据一般需要自定义transform（data[0][0]表示第一张图片，data[1][1]表示第一张图片的标签）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过transform.Lambda来自定义修改策略</span></span><br><span class="line">mnist_transform = transforms.Compose([transforms.ToTensor(),</span><br><span class="line">                                      transforms.Lambda(<span class="keyword">lambda</span>  x : x.resize_(<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">                                      ])</span><br><span class="line">traindata = torchvision.datasets.MNIST(root=<span class="string">"./mnist"</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=mnist_transform)</span><br><span class="line">testdata = torchvision.datasets.MNIST(root=<span class="string">"./mnist"</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                      download=<span class="literal">True</span>, transform=mnist_transform)</span><br><span class="line"><span class="comment"># RandomSampler，当dataloader的shuffle参数为True时，系统会自动调用这个采样器，实现打乱数据。</span></span><br><span class="line">train_loader = DataLoader(traindata, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">test_loader = DataLoader(testdata, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="1-2-定义模型"><a href="#1-2-定义模型" class="headerlink" title="1.2 定义模型"></a>1.2 定义模型</h3><ul>
<li>本实验使用的三层线性层，模型中需要定义初始化函数以及前向函数</li>
<li>线性层的结构定义跟图片维度、类别相关（本实验数据集为MNIST，一般处理为28*28）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">300</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">300</span>, <span class="number">100</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="1-3-定义训练函数"><a href="#1-3-定义训练函数" class="headerlink" title="1.3 定义训练函数"></a>1.3 定义训练函数</h3><ul>
<li>训练函数中需要定义损失函数，然后加载数据，并将数据输入至网络中，损失函数计算损失，将损失反向传播后，利用优化函数更新网络参数，需要注意一点（每一个mini-batch都需要将优化函数中的参数的梯度至零）。可以看出文本分类和图像分类的训练函数差别不大，网络的训练步骤是一样的。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, device, train_loader, optimizer, epoch)</span>:</span></span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        x, y = x.to(device), y.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        y_ = model(x)</span><br><span class="line">        loss = loss_function(y_, y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># print("x ", x)</span></span><br><span class="line">            <span class="comment"># print("batch_idx ", batch_idx)</span></span><br><span class="line">            <span class="comment"># print("len(x) ", len(x))</span></span><br><span class="line">            <span class="comment"># print("len(train_loader.dataset) ", len(train_loader.dataset))</span></span><br><span class="line">            <span class="comment"># print("len(train_loader) ", len(train_loader))</span></span><br><span class="line">            <span class="comment"># batch_idx:第几批次， len(train_loader.dataset):训练集大小， len(train_loader):总共有多少批次</span></span><br><span class="line">            print(<span class="string">"Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;"</span>.format(</span><br><span class="line">                epoch, batch_idx * len(x), len(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / len(train_loader), loss.item()</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure>
<h3 id="1-4-定义测试函数"><a href="#1-4-定义测试函数" class="headerlink" title="1.4 定义测试函数"></a>1.4 定义测试函数</h3><ul>
<li>图像分类的测试函数与文本分类并无太大差别，在这里就不详细介绍了。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model,device, test_loader)</span>:</span></span><br><span class="line">    criterion = nn.CrossEntropyLoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">    test_loss = <span class="number">0.0</span></span><br><span class="line">    acc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y) <span class="keyword">in</span> enumerate(test_loader):</span><br><span class="line">        x, y = x.to(device), y.to(device)</span><br><span class="line">        <span class="comment"># torch.no_grad()，对tensor的操作正常进行，但是track不被记录，无法求其梯度</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            y_ = model(x)</span><br><span class="line">        test_loss += criterion(y_, y)</span><br><span class="line">        <span class="comment"># pred = y_.max(-1, keepdim=True)[1]  # .max()的输出为最大值和最大值的index， 获取index</span></span><br><span class="line">        <span class="comment"># acc += pred.eq(y.view_as(pred)).sum().item()</span></span><br><span class="line">        _, pred = torch.max(y_ ,<span class="number">1</span>)</span><br><span class="line">        acc += (pred == y).sum().item() <span class="comment"># type(acc) = python, 这里需要加上item()，不然type(acc) = tensor</span></span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line">    print(<span class="string">"\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)"</span>.format(</span><br><span class="line">        test_loss, acc, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * acc / len(test_loader.dataset)</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> acc / len(test_loader.dataset)</span><br></pre></td></tr></table></figure>
<h3 id="1-5-训练-保存模型-加载模型-测试"><a href="#1-5-训练-保存模型-加载模型-测试" class="headerlink" title="1.5 训练+保存模型+加载模型+测试"></a>1.5 训练+保存模型+加载模型+测试</h3><ul>
<li>初始化模型，优化器并定义模型保存路径</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = Model()</span><br><span class="line">print(model)</span><br><span class="line"><span class="comment"># 将网络参数放到优化器中</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-04</span>)</span><br><span class="line"></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line">PATH = <span class="string">'./mnist_model.pth'</span> <span class="comment"># 模型保存路径</span></span><br></pre></td></tr></table></figure>
<ul>
<li>迭代训练，保存模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练以及测试</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">5</span>):</span><br><span class="line">    train(model,DEVICE,train_loader,optimizer,epoch)</span><br><span class="line">    acc = test(model,DEVICE,test_loader)</span><br><span class="line">    print(<span class="string">"acc "</span>, acc)</span><br><span class="line">    <span class="keyword">if</span> best_acc &lt; acc:</span><br><span class="line">        best_acc = acc</span><br><span class="line">        torch.save(model.state_dict(), PATH)</span><br><span class="line">    print(<span class="string">"acc is &#123;:.4f&#125;, best acc is &#123;:.4f&#125;\n"</span>.format(acc, best_acc))</span><br></pre></td></tr></table></figure>
<ul>
<li><p>训练过程如下图所示</p>
<p><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%BA%8C/1.png" alt=""></p>
</li>
<li><p>加载模型，测试准确率</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_model = Model()</span><br><span class="line">best_model.load_state_dict(torch.load(PATH))</span><br><span class="line">test(best_model, DEVICE, test_loader)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>测试结果如下图所示</p>
<p><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%BA%8C/2.png" alt=""></p>
</li>
</ul>
<h2 id="2-实现FGSM攻击"><a href="#2-实现FGSM攻击" class="headerlink" title="2 实现FGSM攻击"></a>2 实现FGSM攻击</h2><h3 id="2-1-导入相应库，定义常量，加载模型"><a href="#2-1-导入相应库，定义常量，加载模型" class="headerlink" title="2.1 导入相应库，定义常量，加载模型"></a>2.1 导入相应库，定义常量，加载模型</h3><ul>
<li>需要定义的常量：模型保存路径，要扰动的图片，扰动程度（FGSM论文中的$\varepsilon$）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> ImageClassification.MNISTClassification <span class="keyword">import</span> Model,testdata</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">PATH = <span class="string">'./mnist_model.pth'</span> <span class="comment"># 模型保存路径</span></span><br><span class="line">index = <span class="number">100</span> <span class="comment"># 选择测试样本</span></span><br><span class="line">epsilon = <span class="number">0.1</span> <span class="comment"># 扰动程度</span></span><br><span class="line"></span><br><span class="line">best_model = Model()</span><br><span class="line">best_model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure>
<h3 id="2-2-实现FGSM"><a href="#2-2-实现FGSM" class="headerlink" title="2.2 实现FGSM"></a>2.2 实现FGSM</h3><ul>
<li>将图片输入到网络中，求出损失并反向传播</li>
<li><p>根据公式FGSM论文中的扰动表达式，$\varepsilon{sign(\nabla_{x}J(\boldsymbol{\theta},\boldsymbol{x},y))}$，求出扰动</p>
</li>
<li><p>需要注意：当需要用到tensor的梯度时，需要将数据定义为Variable，不明白可以参考</p>
<p><a href="https://www.jb51.net/article/177996.htm" target="_blank" rel="noopener">https://www.jb51.net/article/177996.htm</a></p>
<p><a href="https://www.cnblogs.com/ryluo/p/10190218.html" target="_blank" rel="noopener">https://www.cnblogs.com/ryluo/p/10190218.html</a></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 需要对image进行求导，因此转为Variable变量，并且将requires_grad设置为True</span></span><br><span class="line">image = Variable(testdata[index][<span class="number">0</span>].resize_(<span class="number">1</span>,<span class="number">784</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">label = torch.tensor([testdata[index][<span class="number">1</span>]])</span><br><span class="line">outputs = best_model(image)</span><br><span class="line">loss = loss_function(outputs, label)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># FGSM 添加扰动</span></span><br><span class="line">x_grad = torch.sign(image.grad.data)</span><br><span class="line"><span class="comment"># torch.clamp(输入， 输入数据的最小值， 输入数据的最大值) 修剪，最大不超过1，最小不小于0</span></span><br><span class="line">x_adversarial = torch.clamp(image.data + epsilon * x_grad, <span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>测试攻击效果并展示攻击结果</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">outputs = best_model(x_adversarial)</span><br><span class="line">print(type(outputs))</span><br><span class="line">predicted = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># image是Variable，因此outputs含有梯度值</span></span><br><span class="line">print(<span class="string">"original predicata is : &#123;&#125;"</span>.format(label[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"attacked predicate is : &#123;&#125;"</span>.format(predicted[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">print(x_adversarial)</span><br><span class="line">x_adversarial.resize_(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">img_adv = transforms.ToPILImage()(x_adversarial)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"img_adv"</span>)</span><br><span class="line">plt.imshow(img_adv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = testdata[index][<span class="number">0</span>]</span><br><span class="line">img = transforms.ToPILImage()(img.resize_(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span> , <span class="number">2</span> , <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"img_org"</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%BA%8C/3.png" alt=""></p>
<h2 id="3-实现DeepFool攻击"><a href="#3-实现DeepFool攻击" class="headerlink" title="3 实现DeepFool攻击"></a>3 实现DeepFool攻击</h2><h3 id="3-1-导入相应库，定义常量，加载模型"><a href="#3-1-导入相应库，定义常量，加载模型" class="headerlink" title="3.1 导入相应库，定义常量，加载模型"></a>3.1 导入相应库，定义常量，加载模型</h3><ul>
<li><p>需要定义的常量：模型保存路径，需要扰动的图片，迭代次数（DeepFool的扰动需要迭代添加），最大迭代次数，论文中的$\eta$（保证数据点跨越分界面）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">import</span> torch</span><br><span class="line">  <span class="keyword">from</span> ImageClassification.MNISTClassification <span class="keyword">import</span> Model, testdata</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line">  <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">  <span class="keyword">import</span> copy</span><br><span class="line">  <span class="keyword">from</span> torch.autograd.gradcheck <span class="keyword">import</span> zero_gradients</span><br><span class="line">  <span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">  <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">  </span><br><span class="line">  PATH = <span class="string">'./mnist_model.pth'</span>  <span class="comment"># 模型保存路径</span></span><br><span class="line">  index = <span class="number">100</span></span><br><span class="line">  loop_i = <span class="number">0</span></span><br><span class="line">  max_iter = <span class="number">50</span></span><br><span class="line">  overshoot = <span class="number">0.02</span>  </span><br><span class="line">  </span><br><span class="line">  net = Model()</span><br><span class="line">  net.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-2-实现DeepFool"><a href="#3-2-实现DeepFool" class="headerlink" title="3.2 实现DeepFool"></a>3.2 实现DeepFool</h3><ul>
<li><p>获取原始图像的标签，实验中直接利用模型的前向函数得到标签，也可以直接将图片输入至网络中得到标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到原始图片类别</span></span><br><span class="line">image = Variable(testdata[index][<span class="number">0</span>].resize_(<span class="number">1</span>, <span class="number">784</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">label = torch.tensor([testdata[index][<span class="number">1</span>]])</span><br><span class="line"><span class="comment"># flatten() 将多维数组转换为一维数组</span></span><br><span class="line">f_image = net.forward(image).data.numpy().flatten()  <span class="comment"># shape [1, 10] -&gt; [10]</span></span><br><span class="line">I = (np.array(f_image)).flatten().argsort()[::<span class="number">-1</span>]  <span class="comment"># [::-1]从后往前取数</span></span><br><span class="line">label = I[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>初始化网络参数，其中包括：公式中需要使用的权重，扰动，分类器输出$w$,$r$,$f$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化网络参数</span></span><br><span class="line">input_shape = image.data.numpy().shape</span><br><span class="line">pert_image = copy.deepcopy(image)  <span class="comment"># 深复制，复制前后两个对象单独存在，不互相影响</span></span><br><span class="line">w = np.zeros(input_shape)</span><br><span class="line">r_tot = np.zeros(input_shape)</span><br><span class="line"></span><br><span class="line">x = Variable(pert_image, requires_grad=<span class="literal">True</span>)</span><br><span class="line">fs = net.forward(x)  <span class="comment"># shape [1, 10]</span></span><br><span class="line"><span class="comment"># fs_list = [fs[0][I[k]] for k in range(len(I))] # 按照概率从大到小的顺序将fs值进行排序</span></span><br><span class="line">k_i = label</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>参照论文中的伪代码，写出迭代攻击算法，其中外循环控制扰动是否成功以及迭代次数是否超过最大限制，内循环控制找出图像点和k个分界面中距离最近的分界面，找到最近分界面后就可以求出需要扰动的距离。</p>
<p><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%BA%8C/4.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> k_i == label <span class="keyword">and</span> loop_i &lt; max_iter:</span><br><span class="line">    pert = np.inf</span><br><span class="line">    fs[<span class="number">0</span>][I[<span class="number">0</span>]].backward(retain_graph=<span class="literal">True</span>)  <span class="comment"># 多次反向传播（多层监督）时，梯度是累加的</span></span><br><span class="line">    orig_grad = x.grad.data.numpy().copy()  <span class="comment"># 赋值，等号左右占用同一个地址</span></span><br><span class="line">    <span class="comment"># 从k个扰动距离中选择最近的距离</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(len(I)):</span><br><span class="line">        zero_gradients(x)</span><br><span class="line">        fs[<span class="number">0</span>][I[k]].backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line">        cur_grad = x.grad.data.numpy().copy()</span><br><span class="line"></span><br><span class="line">        w_k = cur_grad - orig_grad  <span class="comment"># shape [1, 784]</span></span><br><span class="line">        f_k = (fs[<span class="number">0</span>][I[k]] - fs[<span class="number">0</span>][I[<span class="number">0</span>]]).data.numpy()  <span class="comment"># shape [1]</span></span><br><span class="line"></span><br><span class="line">        pert_k = abs(f_k) / np.linalg.norm(w_k.flatten())</span><br><span class="line">        <span class="keyword">if</span> pert_k &lt; pert:</span><br><span class="line">            pert = pert_k</span><br><span class="line">            w = w_k</span><br><span class="line">    r_i = (pert + <span class="number">1e-4</span>) * w / np.linalg.norm(w)</span><br><span class="line">    r_tot = np.float32(r_tot + r_i)  <span class="comment"># 由于决策面是非线性的，因此需要叠加扰动</span></span><br><span class="line"></span><br><span class="line">    pert_image = image + (<span class="number">1</span> + overshoot) * torch.from_numpy(r_tot)</span><br><span class="line">    <span class="comment"># x = Variable(pert_image, requires_grad=True)</span></span><br><span class="line">    fs = net.forward(pert_image)</span><br><span class="line">    k_i = np.argmax(fs.data.numpy().flatten())  <span class="comment"># 扰动后的类别</span></span><br><span class="line">    loop_i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">r_tot += (<span class="number">1</span> + overshoot) * r_tot</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>测试攻击效果并展示攻击结果（代码与FGSM基本一致）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">outputs = net(pert_image.data.resize_(<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">predicted = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">print(<span class="string">"original predicata is : &#123;&#125;"</span>.format(label))</span><br><span class="line">print(<span class="string">"attacked predicate is : &#123;&#125;"</span>.format(predicted[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">pert_image = pert_image.data</span><br><span class="line">pert_image = pert_image.resize(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">img_adv = transforms.ToPILImage()(pert_image)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">"img_adv"</span>)</span><br><span class="line">plt.imshow(img_adv)</span><br><span class="line"></span><br><span class="line">img = testdata[index][<span class="number">0</span>]</span><br><span class="line">img = transforms.ToPILImage()(img.resize_(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">"img_org"</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%BA%8C/5.png" alt=""></p>
</li>
</ul>
<h2 id="4-参考文献"><a href="#4-参考文献" class="headerlink" title="4 参考文献"></a>4 参考文献</h2><ol>
<li><a href="https://github.com/chaoge123456/MLsecurity/blob/master/blog/FGSM%20and%20DeepFool/adversary_example.ipynb" target="_blank" rel="noopener">https://github.com/chaoge123456/MLsecurity/blob/master/blog/FGSM%20and%20DeepFool/adversary_example.ipynb</a></li>
<li><a href="https://blog.csdn.net/u011630575/article/details/78604226" target="_blank" rel="noopener">https://blog.csdn.net/u011630575/article/details/78604226</a></li>
<li><a href="https://blog.csdn.net/xiaoxifei/article/details/87797935" target="_blank" rel="noopener">https://blog.csdn.net/xiaoxifei/article/details/87797935</a></li>
<li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.html" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.html</a></li>
<li><a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">https://arxiv.org/abs/1412.6572</a></li>
</ol>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li><p>知识点1：copy()、deepcopy()与赋值的区别</p>
<p>deepcopy() ，深复制，<strong>即将被复制对象完全再复制一遍作为独立的新个体单独存在。</strong>所以改变原有被复制对象不会对已经复制出来的新对象产生影响。（复制前后的两个对象占用不同的地址）</p>
<p>= ，赋值，<strong>并不会产生一个独立的对象单独存在，他只是将原有的数据块打上一个新标签</strong>，所以当其中一个标签被改变的时候，数据块就会发生变化，另一个标签也会随之改变。（是同一个对象，占用相同的地址，只是名称不同）</p>
<p>copy() ，浅复制，分为两种情况</p>
<p>1）当浅复制的值是不可变对象（数值，字符串，元组）时和“等于赋值”的情况一样，对象的id值与浅复制原来的值相同。</p>
<p>2）当浅复制的值是可变对象（列表和元组）时会产生一个“是那么独立的对象”存在。有两种情况：</p>
<p>第一种情况：复制的 对象中无 复杂 子对象，原来值的改变并不会影响浅复制的值，同时浅复制的值改变也并不会影响原来的值。原来值的id值与浅复制原来的值不同。</p>
<p>第二种情况复制的对象中有 复杂 子对象 （例如列表中的一个子元素是一个列表），如果不改变其中复杂子对象，浅复制的值改变并不会影响原来的值。但是改变原来的值 中的复杂子对象的值会影响浅复制的值。</p>
</li>
<li><p>知识点2：optimizer.step() 和loss.backward()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">optimizer = Adam(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">loss_function =  nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> mini-batch:</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    根据输入求出loss</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>一般情况下，模型的训练代码都是这种结构的，优化器的作用是优化模型的参数，因此初始化时需要将模型的参数交给优化。优化器还需要损失反向传播的梯度信息，因此在loss.backward()之后接上optimizer.step()。切记，每一个mini-batch都需要将优化器中的梯度信息清零，以免影响后续的优化。</p>
</li>
<li><p>保存网络与加载网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存整个网络</span></span><br><span class="line">torch.save(net, <span class="string">'mnist_net_all.pkl'</span>)</span><br><span class="line"><span class="comment"># 保存网络中的参数, 速度快，占空间少</span></span><br><span class="line">torch.save(net.state_dict(),<span class="string">'mnist_net_param.pkl'</span>)</span><br><span class="line"><span class="comment"># 针对上面一般的保存方法，加载的方法分别是：</span></span><br><span class="line"></span><br><span class="line">model_dict=torch.load(PATH)</span><br><span class="line">model_dict=model.load_state_dict(torch.load(PATH))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Haoran Gao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89ResNet%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/">https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%89%EF%BC%89ResNet%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://as837430732.github.io" target="_blank">Haoran's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5fe1f3d795dcf252" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/08/25/%E6%97%A5%E5%B8%B8%E5%A4%87%E5%BF%98%E8%AE%B0%E5%BD%95/"><img class="prev_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%97%A5%E5%B8%B8/%E6%97%A5%E5%B8%B8%E5%A4%87%E5%BF%98%E5%BD%95/cover.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">日常备忘记录</div></div></a></div><div class="next-post pull_right"><a href="/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%8D%E7%8E%B0FGSM%E3%80%81DeepFool%E6%94%BB%E5%87%BB/"><img class="next_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/11/03/pytorch基础（一）数据读取DataLoader和Dataset/" title="pytorch基础（一）数据读取DataLoader和Dataset"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-11-03</div><div class="relatedPosts_title">pytorch基础（一）数据读取DataLoader和Dataset</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/09/pytorch实战（一）实现影评分类器/" title="pytorch实战（一）实现影评分类器"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-09</div><div class="relatedPosts_title">pytorch实战（一）实现影评分类器</div></div></a></div><div class="relatedPosts_item"><a href="/2021/04/30/pytorch基础（二）理解计算图/" title="pytorch基础（二）理解计算图"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-04-30</div><div class="relatedPosts_title">pytorch基础（二）理解计算图</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/15/pytorch实战（二）在MNIST数据集复现FGSM、DeepFool攻击/" title="pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-15</div><div class="relatedPosts_title">pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '87054b14c0603962ee55',
  clientSecret: '3f1b223ace9b5a1fc5bdc3935e366b6fa8e5ef2b',
  repo: 'as837430732.github.io',
  owner: 'as837430732',
  admin: ['as837430732'],
  id: md5(decodeURI(location.pathname)).substring(0,49),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Haoran Gao</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">不积跬步无以至千里</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>