<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>pytorch实战（一）实现影评分类器 | Haoran's blog</title><meta name="description" content="使用pytorch实现一个二元影评分类器，数据使用IMDB"><meta name="keywords" content="Pytorch"><meta name="author" content="Haoran Gao"><meta name="copyright" content="Haoran Gao"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="pytorch实战（一）实现影评分类器"><meta name="twitter:description" content="使用pytorch实现一个二元影评分类器，数据使用IMDB"><meta name="twitter:image" content="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><meta property="og:type" content="article"><meta property="og:title" content="pytorch实战（一）实现影评分类器"><meta property="og:url" content="https://as837430732.github.io/2020/06/09/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%9E%E7%8E%B0%E5%BD%B1%E8%AF%84%E5%88%86%E7%B1%BB%E5%99%A8/"><meta property="og:site_name" content="Haoran's blog"><meta property="og:description" content="使用pytorch实现一个二元影评分类器，数据使用IMDB"><meta property="og:image" content="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><meta property="article:published_time" content="2020-06-09T08:59:48.000Z"><meta property="article:modified_time" content="2020-06-09T10:10:44.410Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://as837430732.github.io/2020/06/09/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%9E%E7%8E%B0%E5%BD%B1%E8%AF%84%E5%88%86%E7%B1%BB%E5%99%A8/"><link rel="prev" title="pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击" href="https://as837430732.github.io/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%8D%E7%8E%B0FGSM%E3%80%81DeepFool%E6%94%BB%E5%87%BB/"><link rel="next" title="对抗攻击（一）Universal Adversarial Attacks on Text Classifiers" href="https://as837430732.github.io/2020/05/23/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%EF%BC%88%E4%B8%80%EF%BC%89Universal-Adversarial-Attacks-on-Text-Classifiers/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/avatar.png" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">9</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch实现文本分类，数据集为kears内置IMDB影评数据"><span class="toc-text">Pytorch实现文本分类，数据集为kears内置IMDB影评数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-导入相应库、定义常量以及加载IMDB数据"><span class="toc-text">1.  导入相应库、定义常量以及加载IMDB数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-定义模型"><span class="toc-text">2. 定义模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-定义训练函数"><span class="toc-text">3. 定义训练函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-定义测试函数"><span class="toc-text">4. 定义测试函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-训练-保存模型"><span class="toc-text">5. 训练+保存模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-加载-测试模型"><span class="toc-text">6. 加载+测试模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-输出结果"><span class="toc-text">7. 输出结果</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Haoran's blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">pytorch实战（一）实现影评分类器</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-09 16:59:48"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-06-09</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-06-09 18:10:44"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-06-09</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98/">实战</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="Pytorch实现文本分类，数据集为kears内置IMDB影评数据"><a href="#Pytorch实现文本分类，数据集为kears内置IMDB影评数据" class="headerlink" title="Pytorch实现文本分类，数据集为kears内置IMDB影评数据"></a>Pytorch实现文本分类，数据集为kears内置IMDB影评数据</h1><h2 id="1-导入相应库、定义常量以及加载IMDB数据"><a href="#1-导入相应库、定义常量以及加载IMDB数据" class="headerlink" title="1.  导入相应库、定义常量以及加载IMDB数据"></a>1.  导入相应库、定义常量以及加载IMDB数据</h2><ul>
<li><p>导入库，其中imdb数据从keras中导入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>需要定义的常量：词汇表大小、句子最大长度、批处理量、嵌入层层数、隐藏层层数、设备</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MAX_WORDS = <span class="number">10000</span> <span class="comment">#词汇表大小</span></span><br><span class="line">MAX_LEN = <span class="number">200</span></span><br><span class="line">BATCH_SIZE = <span class="number">256</span></span><br><span class="line">EMB_SIZE = <span class="number">128</span></span><br><span class="line">HID_SIZE = <span class="number">128</span></span><br><span class="line">DROPOUT = <span class="number">0.2</span></span><br><span class="line">DEVICE = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载IMDB数据，TensorDataset-&gt;RandomSampler-&gt;DataLoader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_WORDS) <span class="comment"># 加载数据</span></span><br><span class="line"><span class="comment"># 将训练集、测试集中的文本进行预处理，变成相同长度的文本，这里采用的规则是，在句子后面填充或截断</span></span><br><span class="line">x_train = pad_sequences(x_train, maxlen=MAX_LEN, padding=<span class="string">'post'</span>, truncating=<span class="string">'post'</span>)</span><br><span class="line">x_test = pad_sequences(x_test, maxlen=MAX_LEN, padding=<span class="string">'post'</span>, truncating=<span class="string">'post'</span>)</span><br><span class="line">print(x_train.shape, x_test.shape)</span><br><span class="line"></span><br><span class="line">train_data = TensorDataset(torch.LongTensor(x_train), torch.LongTensor(y_train))</span><br><span class="line">test_data = TensorDataset(torch.LongTensor(x_test), torch.LongTensor(y_test))</span><br><span class="line"></span><br><span class="line">train_sampler = RandomSampler(train_data) <span class="comment"># 从一个打乱的数据集进行采样</span></span><br><span class="line">train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE) <span class="comment"># 将数据打包起来（一个batch_size是一组）</span></span><br><span class="line"></span><br><span class="line">test_sampler = RandomSampler(test_data)</span><br><span class="line">test_loader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-定义模型"><a href="#2-定义模型" class="headerlink" title="2. 定义模型"></a>2. 定义模型</h2><ul>
<li><p>使用LSTM模型进行文本分类，模型类中需要初始化函数、前向函数。</p>
</li>
<li><p>初始化函数负责初始化模型的参数（词汇表大小、批处理量、嵌入层层数、隐藏层层数）以及模型的架构（本实验使用的是LSTM+线性层1+线性层2）。</p>
</li>
<li><p>前向函数负责输出最终分类结果（本实验通过Embedding-&gt;dropout-&gt;LSTM-&gt;dropout-&gt;fc1-&gt;relu-&gt;avg_pool2d-&gt;fc2最终得到二分类结果）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_words, emb_size, hid_size, dropout)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.max_words = max_words</span><br><span class="line">        self.emb_size = emb_size</span><br><span class="line">        self.hid_size = hid_size</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        self.Embedding = nn.Embedding(self.max_words, self.emb_size)</span><br><span class="line">        self.LSTM = nn.LSTM(self.emb_size, self.hid_size, num_layers=<span class="number">2</span>,</span><br><span class="line">                            batch_first=<span class="literal">True</span>, bidirectional=<span class="literal">True</span>) <span class="comment"># 两层双向LSTM</span></span><br><span class="line">        self.dp = nn.Dropout(self.dropout)</span><br><span class="line">        self.fc1 = nn.Linear(self.hid_size*<span class="number">2</span>, self.hid_size)</span><br><span class="line">        self.fc2 = nn.Linear(self.hid_size, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.Embedding(x) <span class="comment"># x.shape [batch_size, max_len, emb_size]</span></span><br><span class="line">        x = self.dp(x)</span><br><span class="line">        x, _ = self.LSTM(x) <span class="comment"># [batch_size, max_len, hid_size*2]</span></span><br><span class="line">        x = self.dp(x)</span><br><span class="line">        x = F.relu(self.fc1(x)) <span class="comment"># [batch_size, max_len, hid_size]</span></span><br><span class="line">        x = F.avg_pool2d(x, (x.shape[<span class="number">1</span>], <span class="number">1</span>)).squeeze() <span class="comment"># [batch_size, 1, hid_size] -&gt; [batch_size, hid_size]</span></span><br><span class="line">        out = self.fc2(x) <span class="comment"># [batch_size, 2]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-定义训练函数"><a href="#3-定义训练函数" class="headerlink" title="3. 定义训练函数"></a>3. 定义训练函数</h2><ul>
<li><p>训练函数中首先定义损失函数（本实验使用交叉熵），然后加载数据，并通过将数据输入到模型中产生分类结果（y_），将损失计算后，通过反向传播（loss.backward()）更新模型参数（需要加上optimizer.step()模型参数才会被更新）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, device, train_loader, optimizer, epoch)</span>:</span></span><br><span class="line">    model.train() <span class="comment"># 当有`Dropout`, `BatchNorm`时，需要加上这条</span></span><br><span class="line">    criterion = nn.CrossEntropyLoss() <span class="comment"># 交叉熵</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x,y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        x, y = x.to(device), y.to(device) <span class="comment"># x 是一个二维tensor,其中每一行是一个句子，一组batch_size个句子</span></span><br><span class="line">        y_ = model(x)</span><br><span class="line">        loss = criterion(y_, y)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(batch_idx + <span class="number">1</span>)%<span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;"</span>.format(</span><br><span class="line">                epoch, batch_idx * len(x), len(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / len(train_loader), loss.item()</span><br><span class="line">            ))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4-定义测试函数"><a href="#4-定义测试函数" class="headerlink" title="4. 定义测试函数"></a>4. 定义测试函数</h2><ul>
<li><p>测试函数与训练函数类似，而测试函数中需要计算准确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    criterion = nn.CrossEntropyLoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">    test_loss = <span class="number">0.0</span></span><br><span class="line">    acc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, y ) <span class="keyword">in</span> enumerate(test_loader):</span><br><span class="line">        x, y = x.to(device), y.to(device)</span><br><span class="line">        <span class="comment"># torch.no_grad()，对tensor的操作正常进行，但是track不被记录，无法求其梯度</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            y_ = model(x)</span><br><span class="line">        test_loss += criterion(y_, y)</span><br><span class="line">        pred = y_.max(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] <span class="comment"># .max()的输出为最大值和最大值的index， 获取index</span></span><br><span class="line">        acc += pred.eq(y.view_as(pred)).sum().item()</span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line">    print(<span class="string">"\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)"</span>.format(</span><br><span class="line">        test_loss, acc, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * acc/len(test_loader.dataset)</span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">return</span> acc/ len(test_loader.dataset)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="5-训练-保存模型"><a href="#5-训练-保存模型" class="headerlink" title="5. 训练+保存模型"></a>5. 训练+保存模型</h2><ul>
<li><p>初始化模型，定义优化函数（本实验使用的Adam优化器），定义模型保存路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; Model(MAX_WORDS, EMB_SIZE, HID_SIZE, DROPOUT).to(DEVICE)</span><br><span class="line">print(model)</span><br><span class="line">optimizer &#x3D; optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line">best_acc &#x3D; 0.0</span><br><span class="line">PATH &#x3D; &#39;.&#x2F;model.pth&#39; # 模型保存路径</span><br><span class="line"></span><br><span class="line"># 训练、测试以及保存模型</span><br><span class="line">for epoch in range(1, 5):</span><br><span class="line">    train(model,DEVICE,train_loader,optimizer,epoch)</span><br><span class="line">    acc &#x3D; test(model,DEVICE,test_loader)</span><br><span class="line">    if best_acc &lt; acc:</span><br><span class="line">        best_acc &#x3D; acc</span><br><span class="line">        torch.save(model.state_dict(), PATH)</span><br><span class="line">    print(&quot;acc is &#123;:.4f&#125;, best acc is &#123;:.4f&#125;\n&quot;.format(acc, best_acc))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="6-加载-测试模型"><a href="#6-加载-测试模型" class="headerlink" title="6. 加载+测试模型"></a>6. 加载+测试模型</h2><ul>
<li><p>加载保存的模型，调用测试函数进行测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_model = Model(MAX_WORDS, EMB_SIZE, HID_SIZE, DROPOUT)</span><br><span class="line">best_model.load_state_dict(torch.load(PATH))</span><br><span class="line">test(best_model, DEVICE, test_loader)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="7-输出结果"><a href="#7-输出结果" class="headerlink" title="7. 输出结果"></a>7. 输出结果</h2><ul>
<li><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/1.png" alt=""></li>
<li><img src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/2.png" alt=""></li>
</ul>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Haoran Gao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://as837430732.github.io/2020/06/09/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%9E%E7%8E%B0%E5%BD%B1%E8%AF%84%E5%88%86%E7%B1%BB%E5%99%A8/">https://as837430732.github.io/2020/06/09/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%B8%80%EF%BC%89%E5%AE%9E%E7%8E%B0%E5%BD%B1%E8%AF%84%E5%88%86%E7%B1%BB%E5%99%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://as837430732.github.io" target="_blank">Haoran's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5fe1f3d795dcf252" async="async"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/06/15/pytorch%E5%AE%9E%E6%88%98%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%8D%E7%8E%B0FGSM%E3%80%81DeepFool%E6%94%BB%E5%87%BB/"><img class="prev_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击</div></div></a></div><div class="next-post pull_right"><a href="/2020/05/23/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%EF%BC%88%E4%B8%80%EF%BC%89Universal-Adversarial-Attacks-on-Text-Classifiers/"><img class="next_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/%E4%B8%80/cover.png" onerror="onerror=null;src='https://raw.githubusercontent.com/as837430732/Blog_images/master/BlogSource/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">对抗攻击（一）Universal Adversarial Attacks on Text Classifiers</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/04/30/pytorch基础（二）理解计算图/" title="pytorch基础（二）理解计算图"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-04-30</div><div class="relatedPosts_title">pytorch基础（二）理解计算图</div></div></a></div><div class="relatedPosts_item"><a href="/2020/11/03/pytorch基础（一）数据读取DataLoader和Dataset/" title="pytorch基础（一）数据读取DataLoader和Dataset"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-11-03</div><div class="relatedPosts_title">pytorch基础（一）数据读取DataLoader和Dataset</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/15/pytorch实战（三）ResNet模型的原理以及实现/" title="pytorch实战（三） ResNet模型的原理以及实现"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-15</div><div class="relatedPosts_title">pytorch实战（三） ResNet模型的原理以及实现</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/15/pytorch实战（二）在MNIST数据集复现FGSM、DeepFool攻击/" title="pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击"><img class="relatedPosts_cover" src="https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-15</div><div class="relatedPosts_title">pytorch实战（二） 在MNIST数据集复现FGSM、DeepFool攻击</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '87054b14c0603962ee55',
  clientSecret: '3f1b223ace9b5a1fc5bdc3935e366b6fa8e5ef2b',
  repo: 'as837430732.github.io',
  owner: 'as837430732',
  admin: ['as837430732'],
  id: md5(decodeURI(location.pathname)).substring(0,49),
  language: 'zh-CN',
  perPage: 10,
  distractionFreeMode: false,
  pagerDirection: 'last',
  createIssueManually: false,
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  try {
    document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
  } catch (e) {
    return false
  }
}</script></div></article></main><footer id="footer" style="background-image: url(https://raw.githubusercontent.com/as837430732/Blog_images/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch%E5%AE%9E%E6%88%98/%E4%B8%80/pytorch.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Haoran Gao</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">不积跬步无以至千里</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script></body></html>